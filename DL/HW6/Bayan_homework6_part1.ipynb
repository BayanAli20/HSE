{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Bayan_homework6_part1.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6d53N9PQJu-"
      },
      "source": [
        "### Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "E3N7486xQJvE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f4c8dc-b9f7-4660-d765-a8a429a617b4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "!wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall19/week06_rnn/mtg_card_names.txt -O names"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-02 13:11:18--  https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall19/week06_rnn/mtg_card_names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 645304 (630K) [text/plain]\n",
            "Saving to: ‘names’\n",
            "\n",
            "\rnames                 0%[                    ]       0  --.-KB/s               \rnames               100%[===================>] 630.18K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-11-02 13:11:18 (19.0 MB/s) - ‘names’ saved [645304/645304]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYDOwHIKQJvG"
      },
      "source": [
        "# Our data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "q5w_UQbeQJvH"
      },
      "source": [
        "import os\n",
        "start_token = \" \"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    lines = f.read()[:-1].split('\\n')\n",
        "    lines = [start_token + line for line in lines]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZJyAQjTQJvH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1354529-fd28-4de1-f6dd-156c66a609dd"
      },
      "source": [
        "print ('n samples = ',len(lines))\n",
        "for x in lines[::1000]:\n",
        "    print (x)\n",
        "    \n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n samples =  16714\n",
            " [1G] Instant: Moonmist\n",
            " [None] Land: Crystal Quarry\n",
            " [3GW] Legendary Enchantment Creature, God: Karametra, God of Harvests\n",
            " [2R] Creature, Human Rogue: Spireside Infiltrator\n",
            " [3R] Creature, Human Archer: Mardu Heart-Piercer\n",
            " [UB] Creature, Spirit: Dimir Infiltrator\n",
            " [2UU] Creature, Human Wizard: Lunar Mystic\n",
            " [3R] Creature, Goblin Artificer: Krark-Clan Engineers\n",
            " [4GG] Creature, Elemental Warrior: Root-Kin Ally\n",
            " [None] Land: Ancient Tomb\n",
            " [None] Plane, Ulgrotha: The Dark Barony\n",
            " [3U] Creature, Bird Wizard: Aven Fogbringer\n",
            " [5R] Creature, Djinn: Halam Djinn\n",
            " [3WW] Creature, Human: Veteran Bodyguard\n",
            " [2RRR] Creature, Human Berserker: Aerathi Berserker\n",
            " [None] Legendary Creature, Eldrazi Angel: Brisela, Voice of Nightmares\n",
            " [2U] Creature, Human Wizard: Apprentice Sorcerer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryrg1dlzQJvI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "6c7ed94a-9e19-41d4-b168-77c6a5d0c133"
      },
      "source": [
        "MAX_LENGTH = max(map(len, lines))\n",
        "print(\"max length =\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, lines)),bins=25);"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max length = 169\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x0QgKsFQJvI"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need next to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6O_nBKRQJvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ee5a86-1c56-403c-aca5-8a22e0f6529c"
      },
      "source": [
        "#all unique characters go here\n",
        "tokens = set(''.join(lines))\n",
        "\n",
        "tokens = list(tokens)\n",
        "\n",
        "num_tokens = len(tokens)\n",
        "print ('num_tokens = ', num_tokens)\n",
        "\n",
        "assert 77 < num_tokens < 79, \"Names should contain within 50 and 60 unique tokens depending on encoding\""
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_tokens =  78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLByPsXtQJvJ"
      },
      "source": [
        "### Convert characters to integers\n",
        "\n",
        "Torch is built for crunching numbers, not strings. \n",
        "To train our neural network, we'll need to replace characters with their indices in tokens list.\n",
        "\n",
        "Let's compose a dictionary that does this mapping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "D-FkoJAoQJvK"
      },
      "source": [
        "token_to_id = {}\n",
        "for i, token in enumerate(tokens):\n",
        "  token_to_id[token] = i"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGNvkEQAQJvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb13b2f-e048-433e-a68a-c014cb02c177"
      },
      "source": [
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
        "\n",
        "print(\"Seems alright!\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems alright!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PHxqiS63QJvL"
      },
      "source": [
        "def to_matrix(lines, max_len=None, pad=token_to_id[' '], dtype='int32', batch_first = True):\n",
        "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, lines))\n",
        "    lines_ix = np.zeros([len(lines), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(lines)):\n",
        "        line_ix = [token_to_id[c] for c in lines[i]]\n",
        "        lines_ix[i, :len(line_ix)] = line_ix\n",
        "        \n",
        "    if not batch_first: # convert [batch, time] into [time, batch]\n",
        "        lines_ix = np.transpose(lines_ix)\n",
        "\n",
        "    return lines_ix"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SksvLpsOQJvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5992b1-7104-4097-a81c-c1ee4be07752"
      },
      "source": [
        "#Example: cast 4 random names to matrices, pad with zeros\n",
        "print('\\n'.join(lines[::2000]))\n",
        "print(to_matrix(lines[::2000]))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [1G] Instant: Moonmist\n",
            " [3GW] Legendary Enchantment Creature, God: Karametra, God of Harvests\n",
            " [3R] Creature, Human Archer: Mardu Heart-Piercer\n",
            " [2UU] Creature, Human Wizard: Lunar Mystic\n",
            " [4GG] Creature, Elemental Warrior: Root-Kin Ally\n",
            " [None] Plane, Ulgrotha: The Dark Barony\n",
            " [5R] Creature, Djinn: Halam Djinn\n",
            " [2RRR] Creature, Human Berserker: Aerathi Berserker\n",
            " [2U] Creature, Human Wizard: Apprentice Sorcerer\n",
            "[[ 5 71 73 66 41  5  2 62 14 61 74 62 61 39  5 49 54 54 62 76 77 14 61  5\n",
            "   5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
            "   5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5]\n",
            " [ 5 71 35 66 51 41  5 70 32 47 32 62 65 74 25 28  5 55 62 29 44 74 62 61\n",
            "  76 32 62 61  5 68 25 32 74 61 50 25 32 17  5 66 54 65 39  5 46 74 25 74\n",
            "  76 32 61 25 74 17  5 66 54 65  5 54 43  5 36 74 25 38 32 14 61 14]\n",
            " [ 5 71 35 16 41  5 68 25 32 74 61 50 25 32 17  5 36 50 76 74 62  5 11 25\n",
            "  29 44 32 25 39  5 49 74 25 65 50  5 36 32 74 25 61 69 45 77 32 25 29 32\n",
            "  25  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5]\n",
            " [ 5 71 60 52 52 41  5 68 25 32 74 61 50 25 32 17  5 36 50 76 74 62  5 51\n",
            "  77 40 74 25 65 39  5 70 50 62 74 25  5 49 28 14 61 77 29  5  5  5  5  5\n",
            "   5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5]\n",
            " [ 5 71 24 66 66 41  5 68 25 32 74 61 50 25 32 17  5 55 18 32 76 32 62 61\n",
            "  74 18  5 51 74 25 25 77 54 25 39  5 16 54 54 61 69 46 77 62  5 11 18 18\n",
            "  28  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5]\n",
            " [ 5 71  3 54 62 32 41  5 45 18 74 62 32 17  5 52 18 47 25 54 61 44 74 39\n",
            "   5 37 44 32  5 19 74 25  4  5 13 74 25 54 62 28  5  5  5  5  5  5  5  5\n",
            "   5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5]\n",
            " [ 5 71 33 16 41  5 68 25 32 74 61 50 25 32 17  5 19 64 77 62 62 39  5 36\n",
            "  74 18 74 76  5 19 64 77 62 62  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
            "   5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5]\n",
            " [ 5 71 60 16 16 16 41  5 68 25 32 74 61 50 25 32 17  5 36 50 76 74 62  5\n",
            "  13 32 25 14 32 25  4 32 25 39  5 11 32 25 74 61 44 77  5 13 32 25 14 32\n",
            "  25  4 32 25  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5]\n",
            " [ 5 71 60 52 41  5 68 25 32 74 61 50 25 32 17  5 36 50 76 74 62  5 51 77\n",
            "  40 74 25 65 39  5 11 72 72 25 32 62 61 77 29 32  5 57 54 25 29 32 25 32\n",
            "  25  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92P37cnvQJvM"
      },
      "source": [
        "# Recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/yandexdataschool/Practical_DL/blob/fall21/week06_rnn/rnn.png?raw=1\" width=480>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPazDtlRvUjQ"
      },
      "source": [
        "## implement a model that uses 2 LSTM layers (the second lstm uses the first as input) and train it on your data (mtg_card_names.txt) also I did it on names data which we used in seminar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vfIoFkekQJvO"
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CharRNNCell(nn.Module):\n",
        "    \"\"\"\n",
        "    Implement the scheme above as torch module\n",
        "    \"\"\"\n",
        "    def __init__(self, num_tokens=len(tokens), embedding_size=16, lstm_num_units=64):\n",
        "        super(self.__class__,self).__init__()\n",
        "        self.num_units = lstm_num_units\n",
        "        \n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size)       \n",
        "        self.lstm1 = nn.LSTMCell(embedding_size, lstm_num_units)\n",
        "        self.lstm2 = nn.LSTMCell(embedding_size, lstm_num_units)\n",
        "        self.rnn_to_logits = nn.Linear(lstm_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "        \n",
        "        :param x: batch of character ids, int64[batch_size] (next_h1, next_c1)\n",
        "        :param h_prev: previous rnn hidden states, float32 matrix [batch, rnn_num_units]\n",
        "        \"\"\"\n",
        "        (prev_h, prev_c) =  h_prev\n",
        "        (next_h1, next_c1) = self.lstm1(self.embedding(x), (prev_h, prev_c))\n",
        "        (next_h2, next_c2) = self.lstm2(self.embedding(x),  (next_h1, next_c1))\n",
        "\n",
        "        logits = self.rnn_to_logits(next_h2)\n",
        "        \n",
        "        return (next_h2, next_c2), F.log_softmax(logits, -1)\n",
        "\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
        "        return torch.zeros(batch_size, self.num_units), torch.zeros(batch_size, self.num_units)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekS8t7MOqk9d",
        "outputId": "a3f054d2-878a-4cdf-f37e-b411884bd1d7"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "AbIeypO4QJvP"
      },
      "source": [
        "char_lstm = CharRNNCell()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTg5KGVzQJvQ"
      },
      "source": [
        "### RNN loop\n",
        "\n",
        "Once we've defined a single RNN step, we can apply it in a loop to get predictions on each step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-VMsb_r5QJvQ"
      },
      "source": [
        "def rnn_loop(char_rnn, batch_ix):\n",
        "    \"\"\"\n",
        "    Computes log P(next_character) for all time-steps in lines_ix\n",
        "    :param lines_ix: an int32 matrix of shape [batch, time], output of to_matrix(lines)\n",
        "    \"\"\"\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    hid_state = char_rnn.initial_state(batch_size)\n",
        "    logprobs = []\n",
        "\n",
        "    for x_t in batch_ix.transpose(0,1):\n",
        "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
        "        logprobs.append(logp_next)\n",
        "        \n",
        "    return torch.stack(logprobs, dim=1)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egzIJ1SMQJvS"
      },
      "source": [
        "### Likelihood and gradients\n",
        "\n",
        "We can now train our neural network to minimize crossentropy (maximize log-likelihood) with the actual next tokens.\n",
        "\n",
        "To do so in a vectorized manner, we take `batch_ix[:, 1:]` - a matrix of token ids shifted i step to the left so i-th element is acutally the \"next token\" for i-th prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "4WdW3DuBQJvT"
      },
      "source": [
        "predictions_logp = logp_seq[:, :-1]\n",
        "actual_next_tokens = batch_ix[:, 1:]\n",
        "\n",
        "logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
        "\n",
        "loss = -logp_next.mean()"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "enpsFom5QJvT"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "XfMoYWCTQJvU"
      },
      "source": [
        "#for w in char_lstm.parameters():\n",
        "    #assert w.grad is not None and torch.max(torch.abs(w.grad)).data.numpy() != 0, \\\n",
        "      #  \"Loss is not differentiable w.r.t. a weight with shape %s. Check forward method.\" % (w.size(),)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXKQ3dBQQJvU"
      },
      "source": [
        "### The training loop\n",
        "\n",
        "We train our char-rnn exactly the same way we train any deep learning model: by minibatch sgd.\n",
        "\n",
        "The only difference is that this time we sample strings, not images or sound."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "e4kWrxZUQJvV"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "char_rnn = CharRNNCell()\n",
        "opt = torch.optim.Adam(char_rnn.parameters())\n",
        "history = []"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llz8-SqCQJvV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "ef475e06-9f55-44e4-bc13-6e195f40081d"
      },
      "source": [
        "\n",
        "for i in range(1000):\n",
        "    batch_ix = to_matrix(sample(lines, 32), max_len=MAX_LENGTH)\n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "    \n",
        "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
        "    \n",
        "    # compute loss\n",
        "    predictions_logp = logp_seq[:, :-1]\n",
        "    actual_next_tokens = batch_ix[:, 1:]\n",
        "\n",
        "    #logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
        "\n",
        "    #loss = -logp_next.mean()\n",
        "    loss = F.nll_loss(logp_seq[:, :-1].contiguous().view(-1, num_tokens), \n",
        "                  batch_ix[:, 1:].contiguous().view(-1))\n",
        "    \n",
        "    # train with backprop\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    history.append(loss.data.numpy())\n",
        "    if (i+1)%100==0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history,label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8dcnk32BQBLWEAKCoCyiRgQXxK3uW9Wq39YWq9LaxfWrP6mtWrVqtd/aWr/VWle0VVyo+/K1LkUUlIBhB0HWIJIQSEJWspzfHzOJSUjIJJkw5M77+XjMw7n3ntw5NxffOXPuueeacw4REen5osJdARERCQ0FuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeETQgW5mPjP7wszeaGXbNDMrNLO8wOuK0FZTRETaE92BstcAK4FebWyf5Zz7RbA7S09Pd9nZ2R34eBERWbhw4XbnXEZr24IKdDPLBM4AfgdcH4pKZWdnk5ubG4pdiYhEDDPb2Na2YLtc/gTcBNTvpcz5ZrbEzF4ysyEdqaCIiHRdu4FuZmcCBc65hXsp9jqQ7ZwbD7wHPN3GvqabWa6Z5RYWFnaqwiIi0rpgWuhHA2eb2QbgeeAEM3u2aQHnXJFzrjqw+BhweGs7cs496pzLcc7lZGS02gUkIiKd1G4funNuBjADwMymAv/tnPtB0zJmNtA5tzWweDb+i6ciIt2upqaG/Px8qqqqwl2VkIqPjyczM5OYmJigf6Yjo1yaMbM7gFzn3GvA1WZ2NlAL7ACmdXa/IiIdkZ+fT0pKCtnZ2ZhZuKsTEs45ioqKyM/PZ9iwYUH/XIcC3Tn3EfBR4P2tTdY3tuJFRPalqqoqT4U5gJmRlpZGR6816k5REenxvBTmDTpzTD0u0Fd9U8q9b6+itKom3FUREdmv9LhA31RUwSP/+Yp1heXhroqICADJycnhrgLQAwN9WHoSABu2K9BFRJrqcYGelZaIGaxToIvIfsY5x4033sjYsWMZN24cs2bNAmDr1q1MmTKFCRMmMHbsWD7++GPq6uqYNm1aY9kHHnigy5/f6WGL4RIX7WNwaoJa6CKyh9++vpwVX5eGdJ8HD+rFbWeNCars7NmzycvLY/HixWzfvp0jjjiCKVOm8M9//pNTTjmFW265hbq6OioqKsjLy2PLli0sW7YMgOLi4i7Xtce10MHf7bKhSIEuIvuXuXPncskll+Dz+ejfvz/HHXccCxYs4IgjjuDJJ5/k9ttvZ+nSpaSkpDB8+HDWrVvHL3/5S9555x169WprItvg9bgWOkB2WhKv5G3BOefJ4Uoi0jnBtqT3tSlTpjBnzhzefPNNpk2bxvXXX88Pf/hDFi9ezLvvvssjjzzCCy+8wBNPPNGlz+mRLfTs9CR2VdVSVL473FUREWl07LHHMmvWLOrq6igsLGTOnDlMnDiRjRs30r9/f6688kquuOIKFi1axPbt26mvr+f888/nrrvuYtGiRV3+/B7ZQh/eZKRLenJcmGsjIuJ33nnnMW/ePA455BDMjPvuu48BAwbw9NNPc//99xMTE0NycjIzZ85ky5YtXHbZZdTX+2clv+eee7r8+eac6/JOOiMnJ8d19gEX67eXc/wfPuL+C8ZzYY6mXheJZCtXruSggw4KdzW6RWvHZmYLnXM5rZXvkV0umX0S8EWZLoyKiDTRIwM9xhfFkD4JrNfQRRGRRj0y0ME/dHH99opwV0NE9gPh6jruTp05ph4b6NnpSWwsKvfkiRSR4MXHx1NUVOSpLGiYDz0+Pr5DP9cjR7mAv4VesbuOgl3V9O/VsYMWEe/IzMwkPz+/w3OH7+8anljUEUEHupn5gFxgi3PuzBbb4oCZ+J8lWgRc5Jzb0KGadFB2mn/o4rrCcgW6SASLiYnp0FN9vKwjXS7X0PazQi8HdjrnRgAPAL/vasXa0zjroka6iIgAQQa6mWUCZwCPtVHkHODpwPuXgBOtm+/JH5SaQKwvSpN0iYgEBNtC/xNwE1DfxvbBwGYA51wtUAKktSxkZtPNLNfMcrva3+WLMrLSEjV0UUQkoN1AN7MzgQLn3MKufphz7lHnXI5zLicjI6OruyM7LUmBLiISEEwL/WjgbDPbADwPnGBmz7YoswUYAmBm0UBv/BdHu1VW30Tyd1Z6ariSiEhntRvozrkZzrlM51w2cDHwgXPuBy2KvQb8KPD+gkCZbk/Z/r3iqKypY1d1bXd/lIjIfq/TNxaZ2R1mdnZg8XEgzczWAtcDN4eicu0Z0Ns/XLGgtGpffJyIyH6tQzcWOec+Aj4KvL+1yfoq4MJQViwY/VL8gb6ttJoR/VL29ceLiOxXeuyt/+DvcgHYpha6iEhPD/RvW+giIpGuRwd6Ulw0KXHRaqGLiNDDAx2gX684BbqICB4I9AG94xXoIiJ4IND7p8SrD11EBA8Eer9e8RTsqtLdoiIS8Xp8oA/oFUdNnWNH+e5wV0VEJKx6fKCnJfvHoivQRSTS9fhAT02MAaC4sibMNRERCa8eH+i9E/yBXlKhQBeRyNbjAz01IRZQC11EpMcHemMLXYEuIhGuxwd6Snw0ZlBSoYuiIhLZenygR0UZvRNi1OUiIhEvmGeKxpvZ52a22MyWm9lvWykzzcwKzSwv8Lqie6rbut4JMepyEZGIF8wDLqqBE5xzZWYWA8w1s7edc/NblJvlnPtF6KvYvtSEGIo1ykVEIly7gR54NmhZYDEm8Nqv7rPvpS4XEZHg+tDNzGdmeUAB8J5z7rNWip1vZkvM7CUzGxLSWrYjNTGWUgW6iES4oALdOVfnnJsAZAITzWxsiyKvA9nOufHAe8DTre3HzKabWa6Z5RYWFnal3s30ToimWKNcRCTCdWiUi3OuGPgQOLXF+iLnXMMcto8Bh7fx848653KcczkZGRmdqW+rUhNiKamsob5+v+oJEhHZp4IZ5ZJhZqmB9wnAycCqFmUGNlk8G1gZykq2JzUxhnoHZbtr9+XHiojsV4IZ5TIQeNrMfPj/ALzgnHvDzO4Acp1zrwFXm9nZQC2wA5jWXRVuTa8m87n0io/Zlx8tIrLfCGaUyxLg0FbW39rk/QxgRmirFrzUQKAXV9QwpG+4aiEiEl49/k5R0HwuIiLgkUBPTWyYcVEjXUQkcnki0JPj/T1H5dW6KCoikcsTgZ4U6wOgvLouzDUREQkfTwR6Yqxa6CIingj02OgoYn1RlO9WC11EIpcnAh0gMc5HhW4sEpEI5plAT4qNpkxdLiISwTwT6ImxPip0UVREIphnAj0pLppydbmISATzUKD7qNBFURGJYJ4J9MTYaA1bFJGI5plAT1aXi4hEOM8Eui6Kikik80ygJ8Vp2KKIRDbvBHpsNNW19dTW1Ye7KiIiYRHMI+jizexzM1tsZsvN7LetlIkzs1lmttbMPjOz7O6o7N4kxfkn6KqoUbeLiESmYFro1cAJzrlDgAnAqWY2qUWZy4GdzrkRwAPA70NbzfZpgi4RiXTtBrrzKwssxgRerkWxc4CnA+9fAk40MwtZLYPQ0ELXFLoiEqmC6kM3M5+Z5QEFwHvOuc9aFBkMbAZwztUCJUBaK/uZbma5ZpZbWFjYtZq3kBRooWuCLhGJVEEFunOuzjk3AcgEJprZ2M58mHPuUedcjnMuJyMjozO7aFNioIWukS4iEqk6NMrFOVcMfAic2mLTFmAIgJlFA72BolBUMFjJcYEWurpcRCRCBTPKJcPMUgPvE4CTgVUtir0G/Cjw/gLgA+dcy372btV4UVRdLiISoaKDKDMQeNrMfPj/ALzgnHvDzO4Acp1zrwGPA8+Y2VpgB3Bxt9W4DY3DFjVBl4hEqHYD3Tm3BDi0lfW3NnlfBVwY2qp1TFKchi2KSGTzzJ2iiTEatigikc0zgR7tiyIuOkrDFkUkYnkm0ME/46IuiopIpPJUoMfH+Kiq0eRcIhKZPBjo6kMXkcjkqUCPi45SC11EIpanAj0+xkd1rVroIhKZPBXoCepyEZEI5qlAj49Rl4uIRC6PBbpa6CISubwX6OpDF5EI5bFAV5eLiEQuTwV6XLSPKs22KCIRylOBri4XEYlkHgv0KGrqHHX1+/TZGiIi+4Vgnlg0xMw+NLMVZrbczK5ppcxUMysxs7zA69bW9tXd4gNT6Gqki4hEomCeWFQL3OCcW2RmKcBCM3vPObeiRbmPnXNnhr6KwUtoEugND7wQEYkU7bbQnXNbnXOLAu93ASuBwd1dsc6Ij/EfTlWtRrqISOTpUB+6mWXjfxzdZ61snmxmi83sbTMbE4K6dZi6XEQkkgXdL2FmycDLwLXOudIWmxcBQ51zZWZ2OvAKMLKVfUwHpgNkZWV1utJtaQj0Sg1dFJEIFFQL3cxi8If5P5xzs1tud86VOufKAu/fAmLMLL2Vco8653KcczkZGRldrPqeEmMDga4WuohEoGBGuRjwOLDSOffHNsoMCJTDzCYG9lsUyooGoyHQK9RCF5EIFEyXy9HApcBSM8sLrPsVkAXgnHsEuAC4ysxqgUrgYufcPh8MnhDjP5yKaj1XVEQiT7uB7pybC1g7ZR4CHgpVpTorKU4tdBGJXJ66UzShoctFfegiEoE8FeiJsepyEZHI5alAb7hTVF0uIhKJPBXovigjPiZKwxZFJCJ5KtDB3+1SsVtdLiISeTwX6AkxPiqq1UIXkcjjuUBPjPWpD11EIpL3Aj0uWsMWRSQieS/QY3xUqg9dRCKQ9wI91ke5+tBFJAJ5LtATYn0atigiEclzgZ6kYYsiEqE8F+gJGuUiIhHKc4HeMGwxDLP3ioiElScDva7esbtOD4oWkcjiwUD3z7io54qKSKQJ5hF0Q8zsQzNbYWbLzeyaVsqYmT1oZmvNbImZHdY91W2fHkMnIpEqmEfQ1QI3OOcWmVkKsNDM3nPOrWhS5jRgZOB1JPBw4L/7XGJcYE50jXQRkQjTbgvdObfVObco8H4XsBIY3KLYOcBM5zcfSDWzgSGvbRCSAi103VwkIpGmQ33oZpYNHAp81mLTYGBzk+V89gz9fSJBXS4iEqGCDnQzSwZeBq51zpV25sPMbLqZ5ZpZbmFhYWd20a6kWHW5iEhkCirQzSwGf5j/wzk3u5UiW4AhTZYzA+uacc496pzLcc7lZGRkdKa+7Wq4KFquFrqIRJhgRrkY8Diw0jn3xzaKvQb8MDDaZRJQ4pzbGsJ6Bq3hoqhmXBSRSBPMKJejgUuBpWaWF1j3KyALwDn3CPAWcDqwFqgALgt9VYOji6IiEqnaDXTn3FzA2injgJ+HqlJd8e1FUbXQRSSyeO5O0VhfFNFRplEuIhJxPBfoZqbniopIRPJcoIN/PpfyanW5iEhk8Wagx/n0oGgRiTieDPSk2Ggq1EIXkQjjyUDXU4tEJBJ5MtCTFOgiEoE8GeiJsdGUaxy6iEQYjwa6T08sEpGI48lAT4rTsEURiTyeDHRdFBWRSOTJQE+Jj6a23qnbRUQiiicDPTUhFoCSypow10REZN/xZqAnxgBQXLk7zDUREdl3vBnoCYFAr1ALXUQihycDvZcCXUQiUDCPoHvCzArMbFkb26eaWYmZ5QVet4a+mh3T0OVSoi4XEYkgwTyC7ingIWDmXsp87Jw7MyQ1CoHURF0UFZHI024L3Tk3B9ixD+oSMkmxPqKjTF0uIhJRQtWHPtnMFpvZ22Y2pq1CZjbdzHLNLLewsDBEH93q55CaGMNOBbqIRJBQBPoiYKhz7hDgL8ArbRV0zj3qnMtxzuVkZGSE4KPb1ishhtIqBbqIRI4uB7pzrtQ5VxZ4/xYQY2bpXa5ZF/WKj6FUfegiEkG6HOhmNsDMLPB+YmCfRV3db1f5W+iaoEtEIke7o1zM7DlgKpBuZvnAbUAMgHPuEeAC4CozqwUqgYudc67bahykXvHRbN5REe5qiIjsM+0GunPukna2P4R/WON+pU9iLAWlVVTV1BEf4wt3dUREup0n7xQFOGXMAMp31/H0pxvCXRURkX3Cs4F+zMh0hqYl8sWm4nBXRURkn/BsoAOM7JfCuu1l4a6GiMg+4elA79crji+3lelxdCISETwd6NU19QD86l9Lw1wTEZHu5+lAb7hTdOHGnQCs315O9s1v8q8v8sNZLRGRbuHpQD93wmAA8ndW8vt3VnH8Hz4C4IUFCnQR8R5PB/oZ4wc2vn/4o68a3/dNjg1HdUREupWnAx1g6qg9JwHrlxIXhpqIiHQvzwf6Iz84fI91dfVhn5lARCTkPB/o8TE+3rtuSrN1FbvrwlQbEZHu4/lABxjZP4UnpuUAEB1lvLQwn2VbSsJcKxGR0IqIQAc4YXR/Ntx7BuMyewNw5l/m8sKCzewHE0OKiIRExAR6g9SEmMb3N728hLUFmhpARLwh4gI9JT6m2fID//6SMk0NICIe0G6gm9kTZlZgZsva2G5m9qCZrTWzJWZ2WOirGTqXTh7KqP4pjctvLf2G3725Mow1EhEJjWBa6E8Bp+5l+2nAyMBrOvBw16vVfY7I7subVx/TbN1zn2/imN9/AMCS/GLqNaxRRHqgdgPdOTcH2LGXIucAM53ffCDVzAbupXzYRfuiuOvcsdx93rjGdfk7K/lwdQFnP/QJT+qhGCLSA4WiD30wsLnJcn5g3X7tB5OG8l9HZjE8Palx3T8/2wTAqq2lgH8yr5cWat4XEekZ2n2maCiZ2XT83TJkZWXty49u07rt5Y3v31uxDYAXF+bz5bZdlFXX8lVhOSeM7kffJM3/IiL7t1C00LcAQ5osZwbW7cE596hzLsc5l5ORseccK+FwxTHDALj4iCHN1i/OL+GrQn/YH3bne9z6aqvXhEVE9huhCPTXgB8GRrtMAkqcc1tDsN994pYzDmLN707j58eP2Gu5mfM2UlRWzeVPLSD75jd57vNNzbY75zRHjIiEVTDDFp8D5gGjzCzfzC43s5+a2U8DRd4C1gFrgb8DP+u22nYDMyPGF8WQvok8c/lE7v3uuDbLXjsrj/dXFQBwz1vNhzre/tpyDvjVW7rzVETCpt0+dOfcJe1sd8DPQ1ajMDp2ZAbbSquarfvghuN4Y8lW/vjel3y8Znvj+tKqWp6Yu55xmb15KTefWbn+68LflFaxJL+EY0emkxi7Ty9RiEiEU+K00KvFnaTDM5I5fGifVsve8caKPdad8eBcdpTv5uIjhnDv+eObbavYXUu9gwXrd5C7cQc3njI6dBUXkYinQG8hPubbXqjcX58EwNEj0pl2VDZPBTE+fUf5bgCeX7CZyQekcc6Eb0dwTrnvI7aXVTcuK9BFJJQibi6X9pgZD3//MObceDzpyd8+2ehXpx/ET44bzoH9k4Pe1zXP53HeXz+htq6eunrXLMwBDr/zPd5Z9k3I6i4ikc3CdREvJyfH5ebmhuWzu+Ket1bytznruOnUURTuqubJTzZ0eZ8b7j2j6xUTkYhgZgudczmtbVMLvYP++5RRPHP5RH42dQTjA3Ord9XCjTu59dVlVNX4n6S0eUcF17+QR1VNHbV19VTX6glLItI+BXoHxfiiOHak/6aocycM5vVfHMOhWakAPHjJoZ3a5/kPf8rMeRsZ/Zt3WLRpJ/e8vZLZi7bw0eoCrpiZy+jfvLPXn5+/rohKPVZPJOLpomgXmBnjMnvz5LQjyNtczFEHpAPwg0lZHHdgP95eupXZX7R602ybbnt1OUsDj8cr3FXNR6sLAfhwVQG9EqLJ7JPIHa+vYMXWUs6dMJjzDx/MxY/O57xDB/PARRNCe4Ai0qOoDz3ESipqSI6PxhdlANz5xgoen7u+WZmJw/py2VHZfLi6gKFpSdz/7uqg9x8bHcXu2vpWt/1o8lCunDKczD6JOOeorq0nPsbXuL1gVxV9EmOJ8emLmUhPtbc+dLXQQ6x3YvNx7DNOG03F7lqmjMzgtHHNZxVuWI7xGXe/tYrjR2XwYaBF3pa2whzg6XkbeXreRr66+3QufnQe20qryUiJ46ZTRjGkbyJH3fsB1598IFefOLLxZ6pr63js4/VcfsywZuEvIj2PWuj7meyb3wTguSsnccnf53PnuWP5zSsdmxjs8mOG7fGtoMGJo/vxnTH92VJcxZA+CRSWVXPfO6u57ayDuezoYV2uv4h0L7XQe6DJB6Qx58bjyeyTwAmj+3Hl07msCMzTDvDSTydzwSPzuO+C8fRJjOW+d1aRHB/NF5uK2wxzgPdXFTTOR9OUczDny0KS4qIZ2DuezTsqeHvZN9x21sGY+buP6usdH31ZwPGj+jWuE5H9hwJ9P/Ovnx3Fsq/9wZ2VlgjA4NQE3rrmWNYW7OKkP84BICe7b7Px6ycf3B+Aq5/7gtcWf73Hfo8ekcb2XbtZvW1Xq58bEx3FD5/4fI/1n6zdTkp8NM9ecSQvLczn1leXc+MpowD42dQD9gj23bX1xPhMgS8SBupy6WFKKmuorq2jX0p8q9s/W1fERY/OByAp1kd5YDjjg5ccyuLNe2+97805Ewbxal7zPxTvXTeFd5d/w5VThlO4q5pYXxQT736fG04+kF826acXkdBRl4uH9E6IAWLa3D56YC+SYn384cJDKK2q4f+9vBSAw7JSqa1r+4Jqe1qGOcDJD/i/Lcz5cjufb/j2sbPPL9jMkL6JLN1Swm/OPBiA0qoaqmrq6JsYS5QZUVHGusIyoqOiWLRpJ1FRxkkH9dMMlSJdoP97PKZ3QgzL7zi1cfnYkRnM+6qIzD6JpCXF8e7yb7h0Ujazcjdzx9ljSIj1ccnf5/PFpmKumnoAD3/0VYc/s2mYA5RV13LtrDzAP0Qz1hfFr/61lK0lVQxOTaCypo4rjh3Gfe80H67Z2lj66to6Yn1R6sIRCYK6XATnHIVl1fRLiWdLcSXJcdH89cO1/G3OumblbjxlVIfGzHfUyH7J3PCdA1mxdReXThrKttIqzvzLXM4cP5CH/uuwoPezvayatKRY/REQT+pyl4uZnQr8GfABjznn7m2xfRpwP98+S/Qh59xjna6x7FNm1tgnPzg1AYAZpx9EWnIsd7+1ipd+OplvSqs4dcwA5q7ZzrItJSz49Uk8OmcdfZNiydtczBnjBnLZUwu6VI/Y6Ch++uwiAB58f03j+jeWbOXgQWs5a/wgfvv6Cm4/+2C2llSxrbSKLTsreeKT9bx/w1SS46JZml/CWQ/N5diR6Txz+ZHU1Tsen7uOi3Ky9rhHQMRr2m2hm5kP+BI4GcgHFgCXOOdWNCkzDchxzv0i2A9WC33/55yjps4RGx3VbB3Qauv3x08t4IPAkMgD+yfzixNGUl1Tx/3vrua6kw9k1oLN5G0u7pa6nji6H+cfnsmvX1nWOCf993IyOXpEOtc8n8fEYX154SeTG49h+delHJCRTEJs85upbn9tOR+sKmDOTccDsKuqhtcWf82Fhw9p/D3U1TuKyqvJSI5jd109cdGt35BVXVuHc+iGLQmpvbXQgwn0ycDtzrlTAsszAJxz9zQpMw0FugQs2LCDYelJzeaTB/+Qxtr6eg6+9d1m6+88Zwy/eXV5t9fr12ccxF1vfvss2ItyhhDtM64+cWRjP//bgfnp199zOmbGXW+s4LG565k0vC+j+qdwxbHDOfa+DwE4dmQ6H6/Zzh3njOF7OUOIj/FRVl1LYoyPqChjyn0fsqW4kq/uPp3/fnExZ44fyNRR/SivrqVidx2bdlQwbnDvZn8wm3p2/kaKynZz9YkjGv+AllbV7PFULYksXQ30C4BTnXNXBJYvBY5sGt6BQL8HKMTfmr/OObe5lX1NB6YDZGVlHb5x48ZOHZD0bH/8v9WMHdyb5z7fxLUnHcghQ1IpKK3i3rdXtTqZWcNNVG05ZUx/3l2+LeT1vOOcMdza4g/NUQek8elXRXuUHZ6exC9OGMH1Lyzm5tNG89PjDmi86/euc8fy68DdvivvOJUzHvyYddvLgeYXgkurarjz9RX86vSDKCqvbrzn4A8XHsKEIb156tMNPDt/Ey/8ZDITh/Vtt/719Y6Syhr6JMV26vhnL8pnWHoSh2a1/ghGCY99EehpQJlzrtrMfgJc5Jw7YW/7VQtdWlNSWYMZrNlWxq2vLuO2s8YwcVhfvimp4uyH5lKwq5oN957BluJKZs7bwPx1O7jtrIP57l8/5buHDWb2oi2cOLpfq3fDBqNPYgw7K2q6fBwTh/Xl8/U79lj/mzMP5s4Wz6L9Xk4m5x2aycP/+Yo5X+59Lh+A0QNS+P6RWVw6OZvSqhq+2FTMcQdmNG4vr65lZ8VuZi3YzF8+WMvCX59EWnIcW0sq+c/qQi6emLXX/W8sKqd/r/jGaZv1AJb9S7d3ubQo7wN2OOf2+vQHBbp0VFl1LaWVNQwKXLhtqry6lsRYHxuKKsjsk8D2smpezfuaxz5e3+zRf5dOGsr7K7fxdUkV4B+5c9nR2eRu2ElmnwQG9k7gmfkbuPutVY0/s7e5cUJlQK94vimt6vTPj8/sTcXuOv7nwkM4538/abXMmEG9WP51KY//KIeR/VLw+YxFG3dy0kH9+cmzC5kwJJXvHNyfM/8yt9kfpOenT2LS8DQA1haUMbB3PNtKqxiUmsC8dUV8smY7lx87jAG94nns4/UkxvmvGRyW1YeDBvZibcEuNu+spLSyhuy0JDL7JJDWojuuwcdrCrn08c/55OYTGi/Q783sRfn4oqzZs3u9rquBHo2/G+VE/KNYFgD/5Zxb3qTMQOfc1sD784D/55ybtLf9KtBlX9hVVcOX23aRGBvNzordHHVAOiUVNZRW1TCgd3ybUwk3BMsd54zh4iOyeCVvCze9tKRx+/mHZfLyovzG5ScvO4J731rV5tQKPd21J43kwffXUL+XuBiWnsT6QFdSg0cvPZzpzyzco+ylk4Yy4/TRFJRWU1tfT1pSHF9s3snsRVt4Y8lW/nzxBCYMSSU1IZa4mCjioqPI31nJluJKCnZVc/VzX/DyVUdx/sOfAnDnuWMZ2S+ZjJQ4/rO6kB8fM4w3l2zlH59t5O7zxpGdntRmvZ+Zv5Htu6q57uQDKa+upaSyhpVbS3kl72sevHjCXoe/llfXYsZeb4irr3dERYVuCG2XAj2wg9OBP+EftviEc+53ZnYHkOuce83M7gHOBmqBHcBVzrlVbe9RgS77v1aH91IAAAjLSURBVPydFQxOTWj8H7qhT/zBSw5l6qgMxt/+fwD87ryxfP/IoQD864t8rpu1uNl+ph2VzdjBvfnvF79dv+CWk3ghdzP3v7uaa08ayZ/+vYbWLL39O6TEx1BWXcvY2/wXk/NuPZlpTy7gkMzePD3v2+tQUcZeA3d/1r9XHNtKv/0mNah3fOO3KIChaYlsLKpo9jOnjR3QeBG7pXGDezc+KAbg3u+OIyHWR3pyHEdk9+XGlxYzoFd8s3stWpvZ9OWrjmJJfjG/fX0Ff7poAlMOzCA1IaYxoEf/5m2SYqNZ+JuTWbhxB/e+vYpnrziSrcVVPPzRV5x5yEAuffxzrpp6AGMG9eJ//u9L/n39cY3PS+iMLgd6d1CgS0/zyhdbGNEvmbGDe+OcY9iMt4DmfcxfbNrJeX/9lJ8cN5ycoX05NCu1cbTPWX+Zy/rt5dx7/jjOHD8IgKX5JYwd3IvnPt+MGXz3sMGs3LqLX7+ylJ9PHdFsDv3564rYVVXbOBFbw88v/7qEm2cvZfbPjmLRxp2NI3kumZjFc59vYsZpo5m/rqhxrv2mc/x01uThacxb1/zicMsQ3V8dlpXKok1dGz47MbsvefnFjc8nuOX0g5g5fwObd1Tu8e2tpcnD03hu+l47MPZKgS7SDf7x2UYmDEllzKDml4s+XlPIpOFp+/TJUM65xm8S763YxpUzc3nkB4dz6tgBjWXq6x1m8E1pFfe/u5rvHDyAJz5Zz42njOLKmbkUBy4G/2zqAdTVOyYNT2PqqAzMjNq6en7/zir+/vF6Rg9I4ZWfH01pZQ0T736fK44ZxuQD0shOT2L6zFxmnHYQ2emJvJib36wF/MBFh3D0iHQm/u79xnX3XTC+WVfW3qTER7OrqjYUv66wmz/jRAb0bn2CvfYo0EUizFeFZRyQkRx0+YUbd/L0pxt44KIJbXYH1NU7PltXxFEj0hvXNf1D0pqj7/2ACVmpfH9iVuPP/X3OOhJifXy+fgf/871DiPFFUVVTx+xFWzhsaCqVu+s476/+vvEnpuXwp3+v4Y/fO4QR/VJwzvHkJxtYubWUFxfu2Qr+waQszho/qHHG0ZevmszO8hqumOnPmraeCjY8I4kfHz2Mi48YwpF3v09R+W5uOPlA1hSUtToddbBG9EtmbUFZq/W869xxndqnAl1EwqK9wG/Lx2sKSY6LbncMfG1dPVtLqjDzTx3R8Mzc62bl8cna7Xx+y0kAbCmu5JuSSsYM6s1Zf5nL8aP7ccyI9MZnAKz93WlEB75R3fjiYl5cmM+CW04iIyWu8TjAf4d0ccVu1hSUcVhWH9YVllFcWcOFj8zjezmZAMw47SCufyGPSycP5fhR/Rq75s6dMIipo/rhcBx3YD/6dvL+AAW6iEgrPlxVQEp8NDnZ396oVVVTx9qCMsYO3uvI62bKqmtJjmt9pMvMeRsYn5nKhCGpXa0uoEAXEfGMvQX6vrtqIyIi3UqBLiLiEQp0ERGPUKCLiHiEAl1ExCMU6CIiHqFAFxHxCAW6iIhHhO3GIjMrBDr7DLp0YHsIq9MT6Jgjg445MnTlmIc65zJa2xC2QO8KM8tt604pr9IxRwYdc2TormNWl4uIiEco0EVEPKKnBvqj4a5AGOiYI4OOOTJ0yzH3yD50ERHZU09toYuISAs9LtDN7FQzW21ma83s5nDXJ1TMbIiZfWhmK8xsuZldE1jf18zeM7M1gf/2Caw3M3sw8HtYYmaHhfcIOsfMfGb2hZm9EVgeZmafBY5rlpnFBtbHBZbXBrZnh7PeXWFmqWb2kpmtMrOVZjbZy+fZzK4L/JteZmbPmVm8F8+zmT1hZgVmtqzJug6fVzP7UaD8GjP7UUfq0KMC3cx8wP8CpwEHA5eY2cHhrVXI1AI3OOcOBiYBPw8c283A+865kcD7gWXw/w5GBl7TgYf3fZVD4hpgZZPl3wMPOOdGADuBywPrLwd2BtY/ECjXU/0ZeMc5Nxo4BP/xe/I8m9lg4Gogxzk3FvABF+PN8/wUcGqLdR06r2bWF7gNOBKYCNzW8EcgKM65HvMCJgPvNlmeAcwId7266VhfBU4GVgMDA+sGAqsD7/8GXNKkfGO5nvICMgP/yE8A3gAM/80W0S3PN/AuMDnwPjpQzsJ9DJ045t7A+pZ19+p5BgYDm4G+gfP2BnCKV88zkA0s6+x5BS4B/tZkfbNy7b16VAudb/9xNMgPrPOUwNfMQ4HPgP7Oua2BTd8A/QPvvfC7+BNwE1AfWE4Dip1ztYHlpsfUeLyB7SWB8j3NMKAQeDLQ1fSYmSXh0fPsnNsC/AHYBGzFf94W4v3z3KCj57VL57unBbrnmVky8DJwrXOutOk25/+T7YlhSWZ2JlDgnFsY7rrsY9HAYcDDzrlDgXK+/RoOeO489wHOwf+HbBCQxJ7dEhFhX5zXnhboW4AhTZYzA+s8wcxi8If5P5xzswOrt5nZwMD2gUBBYH1P/10cDZxtZhuA5/F3u/wZSDWzhsenNz2mxuMNbO8NFO3LCodIPpDvnPsssPwS/oD36nk+CVjvnCt0ztUAs/Gfe6+f5wYdPa9dOt89LdAXACMDV8hj8V9ceS3MdQoJMzPgcWClc+6PTTa9BjRc6f4R/r71hvU/DFwtnwSUNPlqt99zzs1wzmU657Lxn8cPnHPfBz4ELggUa3m8Db+HCwLle1wr1jn3DbDZzEYFVp0IrMCj5xl/V8skM0sM/BtvOF5Pn+cmOnpe3wW+Y2Z9At9uvhNYF5xwX0ToxEWH04Evga+AW8JdnxAe1zH4v44tAfICr9Px9x++D6wB/g30DZQ3/CN+vgKW4h9FEPbj6OSxTwXeCLwfDnwOrAVeBOIC6+MDy2sD24eHu95dON4JQG7gXL8C9PHyeQZ+C6wClgHPAHFePM/Ac/ivE9Tg/yZ2eWfOK/DjwPGvBS7rSB10p6iIiEf0tC4XERFpgwJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRCnQREY/4/yEQ6BuisIK7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDC6diOcQJvV"
      },
      "source": [
        "### RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. \n",
        "All we need is the single rnn step function you have defined in `char_rnn.forward`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "KxsPvLTzQJvW"
      },
      "source": [
        "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "    \n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
        "    hid_state = char_rnn.initial_state(batch_size=1)\n",
        "    \n",
        "    #feed the seed phrase, if any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
        "    \n",
        "    #start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
        "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n",
        "        \n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens,p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpUmoIaHQJvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80772d99-39db-4d5d-8ed4-4ac42dbab8da"
      },
      "source": [
        " for _ in range(10):\n",
        "    print(generate_sample(char_rnn))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [Uon] Instant: oore Fopte Kanizef Crargin                                                                                                                               \n",
            " [5onLe] Svanlis  Arhuwin oftal                                        W                                                                                                 \n",
            " [US] C Irtifat: Eakigen Dhage                                                                                          R                                                \n",
            " [2B] Artireat: Gouge Klo Bed Indiir                                                                                                                                     \n",
            " [1W] Eacture, Heacti, Parfore                                                                                                                                           \n",
            " [2W] Crlicman, Creactarythest Binot                                                                                                                                     \n",
            " [3BUB] Creature, HuigScln Schare: Brdagenon                                                                                                                             \n",
            " [3RU] Enentary: orde Ceacars                                                                                                                                            \n",
            " [4R] Instant: Rof MVaght                                                                                                                                                \n",
            " [1RU] Crong: [Bemanur: Ssurgad: Dgearrerg                                                                                                                               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcFy8MuQQJvX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86336bdf-4f06-41d4-a6af-8ad4d58e3016"
      },
      "source": [
        "for _ in range(50):\n",
        "    print(generate_sample(char_rnn, seed_phrase=' Svanlis'))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " SvanlisL] Crthena  Mlan, Sopupary                                                                                                                                       \n",
            " SvanlisUG] Enchantmcantment: Mosthaul: Anstqar: Supian                                                                                                                  \n",
            " SvanlisR]Unchant: tuegt                                                                                                                                                 \n",
            " Svanlis6RGM] Artifact, Enet: Stifrindant, Shf Anastarryr                                                                                                                \n",
            " SvanlisW] Sorce Ronkery Greaveigson                                                                                                                                     \n",
            " SvanlisEQronemant, Wolin Sdaoct                                                                                                                                         \n",
            " SvanlisR] Cneat, Ruacermolk Nytal                                                                                                                                       \n",
            " SvanlisG] Intart: Sohimang: Lecher                                                                                                                                      \n",
            " SvanlisCrR]neature, Gagon Narpier                                                                                                                                       \n",
            " SvanlisIG/R] Enccerusturat: Crals: Lalizouncer Sfald                                                                                                                    \n",
            " SvanlisK] Beand, Roloriwalle Wirf: Atrber: 3anser Tush: Spuress                                                                                                         \n",
            " SvanlisInlne, Grac'sgens 1estalBon                                                                                                                                      \n",
            " Svanlis] Elaomn: Cemensenfant: Nhaliti                                                                                                                                  \n",
            " SvanlisWLR/W] Artifact: Lvostent ousge                                                                                                                                  \n",
            " SvanlisER] Creature, Sidame: Gearse Niginvnol                                                                                                                           \n",
            " SvanlisGMG] Enchant: Staker: Malkol: Ifdatid                                                                                                                            \n",
            " SvanlisS7l] EcerMatamenOmt: Shzind: Ghappird                                                                                                                            \n",
            " SvanlisAgatolfre: Elune Cuban Shinfat: Honde Rivariil Rirwwolg                                                                                                          \n",
            " SvanlisB] Creature, Human SoeangMey: Doldiaos Goge                                                                                                                      \n",
            " SvanlisIB]wFnstanw, Hard: W4a AdQathkan Mhanautar                                                                                                                       \n",
            " Svanlise] Arthrore: Uena Cant erenoml Mislce: Amanemen Gofcer                                                                                                           \n",
            " SvanlisGWR] Instant: Blag Ore: Inithy Loviboy                                                                                                                           \n",
            " Svanlis2WofGG] Instant: Ruat Grudi                                                                                                                                      \n",
            " Svanlis4] Creature, Zreanh: Rworestraotte: Afitra: Daunis Crer                                                                                                          \n",
            " Svanlis0/C] Geriadamanture, Vabaozemelke olus                                                                                                                           \n",
            " SvanlisU]Ereay Aonch                                                                                                                                                    \n",
            " SvanlisWGU] Beotunent,restwurrte Ceriral Wager: Pe: Eozebee                                                                                                             \n",
            " Svanlis] HuaneF: Lehid ord' Foil'k                                                                                                                                      \n",
            " Svanlis] Leecxarard: Ganstherd Catj                                                                                                                                     \n",
            " SvanlisB] Selaure Shict: Enfatarg Deekin Uperosk                                                                                                                        \n",
            " SvanlisIn] Factory: ToHyther                                                                                                                                            \n",
            " SvanlisRG] Enhanture, Ele Thave                                                                                                                                         \n",
            " SvanlisBE] Creorp Ceature, Ccakie Uocuutint                                                                                                                             \n",
            " SvanlisE] Enhantment: Snitoraol: Fghatitkares                                                                                                                           \n",
            " Svanlis] Innant, Luafurnw                                                                                                                                               \n",
            " Svanlis] Creature,re, Ka Tkiry: Wol:Rangstr: Entithers                                                                                                                  \n",
            " Svanlis] Ene, Ranrergan/ Rerantfasie Wirc                                                 s                                                                             \n",
            " SvanlisWSanu] Cered: Dreolwend                                                                                                                                          \n",
            " SvanlisBU] Creature, Hunt                                                                                                                                               \n",
            " Svanlis] Crchant:  Inlsslein, Bllf Okarckan GG                                                                                                                          \n",
            " SvanlisS5B] Artiocce Clant, Shinpel Colfle tior                                                                                                                         \n",
            " SvanlisI] Marbr, Bace Ibtougs                                                                                                                                           \n",
            " Svanlis] Enchantmen Creamant: Ern Cenath Cbagesti, Shird                                                                                                                \n",
            " SvanlisU] Artyreatumera: Oolie: Sntasbiarg                                                                                                                              \n",
            " Svanlis] Creature, Ceqd Aragulag                                                                                                                                        \n",
            " SvanlisCs] Creatary Creature,Rait: Simestar                                                                                                                             \n",
            " Svanlis] Instant: Thanes                                                                             i                                                                  \n",
            " Svanlis4R] Aonchatt: Cinqiec: Bater                                                                                                                                     \n",
            " SvanlisG] Instat: Eleriilin Dranie Ante eins                                                                                                                            \n",
            " SvanlisM7] Enctord: Sorck Zrys&                                                                                                                                         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNjU4xmJQJvX"
      },
      "source": [
        "### Try it out!\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* Ikea catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "sY-RYQgVQJvX"
      },
      "source": [
        "### More seriously\n",
        "\n",
        "What we just did is a manual low-level implementation of RNN. While it's cool, i guess you won't like the idea of re-writing it from scratch on every occasion. \n",
        "\n",
        "As you might have guessed, torch has a solution for this. To be more specific, there are two options:\n",
        "* `nn.RNNCell(emb_size, rnn_num_units)` - implements a single step of RNN just like you did. Basically concat-linear-tanh\n",
        "* `nn.RNN(emb_size, rnn_num_units` - implements the whole rnn_loop for you.\n",
        "\n",
        "There's also `nn.LSTMCell` vs `nn.LSTM`, `nn.GRUCell` vs `nn.GRU`, etc. etc.\n",
        "\n",
        "In this example we'll rewrite the char_rnn and rnn_loop using high-level rnn API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MQsDqPEAQJvY"
      },
      "source": [
        "class CharRNNLoop(nn.Module):\n",
        "    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.rnn = nn.RNN(emb_size, rnn_num_units, batch_first=True)\n",
        "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h_seq, _ = self.rnn(self.emb(x))\n",
        "        next_logits = self.hid_to_logits(h_seq)\n",
        "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
        "        return next_logp\n",
        "    \n",
        "model = CharRNNLoop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fKNisLelQJvY"
      },
      "source": [
        "# the model applies over the whole sequence\n",
        "batch_ix = to_matrix(sample(lines, 32), max_len=MAX_LENGTH)\n",
        "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "\n",
        "logp_seq = model(batch_ix)\n",
        "\n",
        "# compute loss. This time we use nll_loss with some duct tape\n",
        "loss = F.nll_loss(logp_seq[:, :-1].contiguous().view(-1, num_tokens), \n",
        "                  batch_ix[:, 1:].contiguous().view(-1))\n",
        "\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "TW6Yd-p0QJvZ"
      },
      "source": [
        "Here's another example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mCRVrxDCQJvZ"
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CharLSTMCell(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements something like CharRNNCell, but with LSTM\n",
        "    \"\"\"\n",
        "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
        "        super(self.__class__,self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "        self.emb = nn.Embedding(num_tokens, embedding_size)\n",
        "        self.lstm = nn.LSTMCell(embedding_size, rnn_num_units)\n",
        "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x, prev_state):\n",
        "        (prev_h, prev_c) = prev_state\n",
        "        (next_h, next_c) = self.lstm(self.emb(x), (prev_h, prev_c))\n",
        "        logits = self.rnn_to_logits(next_h)\n",
        "        \n",
        "        return (next_h, next_c), F.log_softmax(logits, -1)\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\" LSTM has two state variables, cell and hid \"\"\"\n",
        "        return torch.zeros(batch_size, self.num_units), torch.zeros(batch_size, self.num_units)\n",
        "    \n",
        "char_lstm = CharLSTMCell()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vjXwyycuQJva"
      },
      "source": [
        "# the model applies over the whole sequence\n",
        "batch_ix = to_matrix(sample(lines, 32), max_len=MAX_LENGTH)\n",
        "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "\n",
        "logp_seq = rnn_loop(char_lstm, batch_ix)\n",
        "\n",
        "# compute loss. This time we use nll_loss with some duct tape\n",
        "loss = F.nll_loss(logp_seq[:, :-1].contiguous().view(-1, num_tokens), \n",
        "                  batch_ix[:, 1:].contiguous().view(-1))\n",
        "\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6HPhkVUQJva"
      },
      "source": [
        "__Bonus quest: __ implement a model that uses 2 LSTM layers (the second lstm uses the first as input) and train it on your data."
      ]
    }
  ]
}